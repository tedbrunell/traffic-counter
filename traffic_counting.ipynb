{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77c3e93-c641-4d41-9486-ea197076f6eb",
   "metadata": {},
   "source": [
    "## Traffic Counting Demo\n",
    "\n",
    "This demo shows the ability of YOLOE-11 to count objects such as cars on a freeway.\n",
    "\n",
    "For the video, I use a 20 second video of a freeway where a object detection region is drawn over both the inbound and outbound lanes.  Without modification to YOLOE-11, cars going into (towards the viewer of the video) and out of the zone are counted.  If you want to try other videos, [Pexels](https://www.pexels.com/) is a great source for royalty free files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900498c8-e012-4c77-9b37-6cd14255fd3a",
   "metadata": {},
   "source": [
    "In this step, we load the nightly builds of torch and torchvision to support a Nvidia Blackwell card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12319714-002e-4052-b613-fadfb8ad6b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --quiet -U --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cu128 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d32b8d-3c5e-4e03-9cf4-84e4b12c4f01",
   "metadata": {},
   "source": [
    "Now, install opencv and ultralytics.  Ultralytics will provide the YOLOE-11 model as well as the ability to count objects via ``ObectCounter`` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab0f6d-a647-425a-8050-6efb2072abea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --quiet -U opencv-python ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e5f19-5a42-43a4-8981-84784fd1b2b0",
   "metadata": {},
   "source": [
    "Now we import some other libraries that are already present in my python environment.  We set the ``YOLO_VERBOSE`` environment variable to stop the output of model inforamtion from YOLOE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b446cdb-cb8f-4907-a300-b7ec66e16402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics import solutions\n",
    "from ultralytics import YOLOE\n",
    "from copy import deepcopy\n",
    "\n",
    "os.environ['YOLO_VERBOSE'] = 'False'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb7086d-e1a1-4a3b-a179-dcc18fb28862",
   "metadata": {},
   "source": [
    "This is the main function that opens the video file, sets up the region where counting will take place and writes the video back out as an .avi file.  Once the vide ends, or a blank frame is encountered, the program will break and end.\n",
    "\n",
    "Some of the arguments can be changed:\n",
    "\n",
    "``region_points`` change to your liking.  I found that the region works well for the video that I used.\n",
    "\n",
    "``conf`` - confidence of the model.  Adjust to optimize for correct object detections.\n",
    "\n",
    "``iou`` - intersection over union for detecting overlapping objects\n",
    "\n",
    "``show_conf`` and ``show_labels`` - shows the confidence score and label on the bounding box for each obejct that is detected.\n",
    "\n",
    "``verbose`` - set to false to supress the output of detections while the notebook is running.  Lack of objects in the frame is still logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbb371ed-fce9-42be-b305-1d310e68a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_objects_in_region(video_path, output_video_path):\n",
    "    \n",
    "    # Count objects in a specific region within a video.\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    assert cap.isOpened(), \"Error reading video file\"\n",
    "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "    video_writer = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "    # define the region where counting will take place.\n",
    "    region_points = [(20, 490), (1880, 490), (1880, 470), (20, 470)]\n",
    "    \n",
    "    # Counter solution from Ultralytics\n",
    "    counter = solutions.ObjectCounter(\n",
    "        region=region_points,\n",
    "        conf=.10,\n",
    "        iou = .90,\n",
    "        show_conf=False,\n",
    "        show_labels=False,\n",
    "        verbose=False,\n",
    "        model=detectionmodel\n",
    "    )\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, im0 = cap.read()\n",
    "        if not success:\n",
    "            print(\"Video frame is empty or processing is complete.\")\n",
    "            break\n",
    "        results = counter(im0)\n",
    "        video_writer.write(results.plot_im)\n",
    "\n",
    "    cap.release()\n",
    "    video_writer.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981f25f-2984-4a3c-8c1d-fd6fcfb03bf0",
   "metadata": {},
   "source": [
    "The following block of code is where we set the model and the object classes that we want to detect.  By specifying ``car`` the program will not detect trucks, including tractor-trailers or utility trucks.  Pickup trucks seem to be considered cars by YOLOE.\n",
    "\n",
    "``verbose=False`` is specified to try to supress the output of model information when the model starts.  This does not seem to work though.\n",
    "\n",
    "Try changing the object classes in the ``objects`` array.  \n",
    "\n",
    "The input (``videos/traffic-20sec.mp4``) and output (``output/traffic_count_output.avi``) filenames are passed to our function.  Experiment here with different video files to see how YOLOE performs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a0d3a-7978-45be-9f2f-6121c25a1703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained YOLOE model that provides image segmentation.\n",
    "detectionmodel = YOLOE('yoloe-11s-seg.pt', verbose=False)\n",
    "\n",
    "# Define the obects that we want to detect and add them ot the model.\n",
    "objects = [\"car\"]\n",
    "detectionmodel.set_classes(objects, detectionmodel.get_text_pe(objects))\n",
    "\n",
    "# call the function to count \n",
    "count_objects_in_region(\"videos/traffic-20sec.mp4\", \"output/traffic_count_output.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcc72af-9f94-4c71-8c5c-e9077ecf1771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
